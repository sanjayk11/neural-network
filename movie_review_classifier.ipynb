{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "movie-review-classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNLehzI724rGgba8g8RhPhk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjayk11/neural-network/blob/main/movie_review_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKqZl0oqWeCI",
        "outputId": "f82459f3-327b-42e4-9669-722bb7dd3802"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import numpy\r\n",
        "\r\n",
        "imdb = keras.datasets.imdb\r\n",
        "\r\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwX8Ta7kXFLN",
        "outputId": "de6e1150-23af-41d5-b15d-e0412245ea01"
      },
      "source": [
        "_word_index = imdb.get_word_index()\r\n",
        "\r\n",
        "word_index = {k:(v+3) for k,v in _word_index.items()}\r\n",
        "word_index[\"<PAD>\"] = 0\r\n",
        "word_index[\"<START>\"] = 1\r\n",
        "word_index[\"<UNK>\"] = 2  # unknown\r\n",
        "word_index[\"<UNUSED>\"] = 3\r\n",
        "\r\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\r\n",
        "\r\n",
        "def decode_review(text):\r\n",
        "\treturn \" \".join([reverse_word_index.get(i, \"?\") for i in text])\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBobBS6LYYML",
        "outputId": "64feb455-e522-4e9d-87d2-db3e5725674f"
      },
      "source": [
        "print(decode_review(test_data[0]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<START> please give this one a miss br br <UNK> <UNK> and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite <UNK> so all you madison fans give this a miss\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaXmJFkiZIwE"
      },
      "source": [
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)\r\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l4ltYjPZdfc",
        "outputId": "320c9d42-b441-479e-b37a-934cc106fe58"
      },
      "source": [
        "print(len(test_data[1]),len(test_data[2]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250 250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ6a-mkTay-B"
      },
      "source": [
        "model = keras.Sequential()\r\n",
        "model.add(keras.layers.Embedding(88000, 16))\r\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\r\n",
        "model.add(keras.layers.Dense(16, activation=\"relu\"))\r\n",
        "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAAKVQVzdLo6"
      },
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QYu2IlMcv5C"
      },
      "source": [
        "x_val = train_data[:10000]\r\n",
        "x_train = train_data[10000:]\r\n",
        "\r\n",
        "y_val = train_labels[:10000]\r\n",
        "y_train = train_labels[10000:]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL1oFwCRczcj",
        "outputId": "8cc2d01b-0184-438b-b64f-4bd11983f486"
      },
      "source": [
        "fitModel = model.fit(x_train, y_train, epochs=40, batch_size=512, validation_data=(x_val, y_val), verbose=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "30/30 [==============================] - 3s 37ms/step - loss: 0.6927 - accuracy: 0.5337 - val_loss: 0.6899 - val_accuracy: 0.7189\n",
            "Epoch 2/40\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.6878 - accuracy: 0.7002 - val_loss: 0.6812 - val_accuracy: 0.7122\n",
            "Epoch 3/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.6764 - accuracy: 0.7476 - val_loss: 0.6639 - val_accuracy: 0.7528\n",
            "Epoch 4/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.6543 - accuracy: 0.7734 - val_loss: 0.6348 - val_accuracy: 0.7623\n",
            "Epoch 5/40\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.6188 - accuracy: 0.7932 - val_loss: 0.5957 - val_accuracy: 0.7888\n",
            "Epoch 6/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.5740 - accuracy: 0.8078 - val_loss: 0.5501 - val_accuracy: 0.8076\n",
            "Epoch 7/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.5217 - accuracy: 0.8296 - val_loss: 0.5039 - val_accuracy: 0.8217\n",
            "Epoch 8/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.4715 - accuracy: 0.8479 - val_loss: 0.4611 - val_accuracy: 0.8352\n",
            "Epoch 9/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.4217 - accuracy: 0.8650 - val_loss: 0.4246 - val_accuracy: 0.8468\n",
            "Epoch 10/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.3843 - accuracy: 0.8779 - val_loss: 0.3950 - val_accuracy: 0.8543\n",
            "Epoch 11/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.3520 - accuracy: 0.8831 - val_loss: 0.3717 - val_accuracy: 0.8610\n",
            "Epoch 12/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.3231 - accuracy: 0.8910 - val_loss: 0.3534 - val_accuracy: 0.8662\n",
            "Epoch 13/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.3030 - accuracy: 0.8980 - val_loss: 0.3387 - val_accuracy: 0.8712\n",
            "Epoch 14/40\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.2840 - accuracy: 0.8997 - val_loss: 0.3271 - val_accuracy: 0.8745\n",
            "Epoch 15/40\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.2686 - accuracy: 0.9083 - val_loss: 0.3176 - val_accuracy: 0.8772\n",
            "Epoch 16/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.2507 - accuracy: 0.9119 - val_loss: 0.3106 - val_accuracy: 0.8775\n",
            "Epoch 17/40\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.2377 - accuracy: 0.9135 - val_loss: 0.3047 - val_accuracy: 0.8789\n",
            "Epoch 18/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.2239 - accuracy: 0.9215 - val_loss: 0.2990 - val_accuracy: 0.8814\n",
            "Epoch 19/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.2124 - accuracy: 0.9266 - val_loss: 0.2946 - val_accuracy: 0.8834\n",
            "Epoch 20/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.2037 - accuracy: 0.9317 - val_loss: 0.2920 - val_accuracy: 0.8835\n",
            "Epoch 21/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.1900 - accuracy: 0.9352 - val_loss: 0.2919 - val_accuracy: 0.8818\n",
            "Epoch 22/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.1847 - accuracy: 0.9399 - val_loss: 0.2871 - val_accuracy: 0.8855\n",
            "Epoch 23/40\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.1722 - accuracy: 0.9466 - val_loss: 0.2860 - val_accuracy: 0.8844\n",
            "Epoch 24/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.1704 - accuracy: 0.9472 - val_loss: 0.2858 - val_accuracy: 0.8845\n",
            "Epoch 25/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.1616 - accuracy: 0.9485 - val_loss: 0.2851 - val_accuracy: 0.8860\n",
            "Epoch 26/40\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.1484 - accuracy: 0.9553 - val_loss: 0.2853 - val_accuracy: 0.8854\n",
            "Epoch 27/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.1445 - accuracy: 0.9556 - val_loss: 0.2858 - val_accuracy: 0.8864\n",
            "Epoch 28/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.1444 - accuracy: 0.9549 - val_loss: 0.2871 - val_accuracy: 0.8861\n",
            "Epoch 29/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.1340 - accuracy: 0.9612 - val_loss: 0.2886 - val_accuracy: 0.8865\n",
            "Epoch 30/40\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.1296 - accuracy: 0.9627 - val_loss: 0.2892 - val_accuracy: 0.8851\n",
            "Epoch 31/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.1247 - accuracy: 0.9646 - val_loss: 0.2925 - val_accuracy: 0.8838\n",
            "Epoch 32/40\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.1207 - accuracy: 0.9647 - val_loss: 0.2929 - val_accuracy: 0.8859\n",
            "Epoch 33/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.1120 - accuracy: 0.9691 - val_loss: 0.2960 - val_accuracy: 0.8857\n",
            "Epoch 34/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.1042 - accuracy: 0.9724 - val_loss: 0.2979 - val_accuracy: 0.8848\n",
            "Epoch 35/40\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.1074 - accuracy: 0.9701 - val_loss: 0.3006 - val_accuracy: 0.8840\n",
            "Epoch 36/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0987 - accuracy: 0.9739 - val_loss: 0.3030 - val_accuracy: 0.8840\n",
            "Epoch 37/40\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.0985 - accuracy: 0.9744 - val_loss: 0.3086 - val_accuracy: 0.8810\n",
            "Epoch 38/40\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0972 - accuracy: 0.9755 - val_loss: 0.3101 - val_accuracy: 0.8834\n",
            "Epoch 39/40\n",
            "30/30 [==============================] - 1s 32ms/step - loss: 0.0902 - accuracy: 0.9774 - val_loss: 0.3130 - val_accuracy: 0.8818\n",
            "Epoch 40/40\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.0883 - accuracy: 0.9783 - val_loss: 0.3170 - val_accuracy: 0.8816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cK3wVkSWdw6R",
        "outputId": "064650a4-e230-482f-e8c0-5b80a92f084a"
      },
      "source": [
        "results = model.evaluate(test_data, test_labels)\r\n",
        "print(results)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 2s 3ms/step - loss: 0.3394 - accuracy: 0.8700\n",
            "[0.33942675590515137, 0.8699600100517273]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qloISC2ohfFd"
      },
      "source": [
        "model.save(\"model.h5\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dHy0T1jhigv"
      },
      "source": [
        "model = keras.models.load_model(\"model.h5\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTvoqA3whzA-"
      },
      "source": [
        "def review_encode(s):\r\n",
        "\tencoded = [1]\r\n",
        "\r\n",
        "\tfor word in s:\r\n",
        "\t\tif word.lower() in word_index:\r\n",
        "\t\t\tencoded.append(word_index[word.lower()])\r\n",
        "\t\telse:\r\n",
        "\t\t\tencoded.append(2)\r\n",
        "\r\n",
        "\treturn encoded"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "_AjhYmaViLW0",
        "outputId": "e308697c-7bfa-4c77-e849-a1b34a455806"
      },
      "source": [
        "(\"test.txt\", encoding=\"utf-8\") as f"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-02e2d3aae21e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    with open(\"test.txt\", encoding=\"utf-8\") as f:\u001b[0m\n\u001b[0m                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "18WAII2Ih3Ow",
        "outputId": "5a1521bb-a339-4985-e715-77b18dd5dbc7"
      },
      "source": [
        "\r\n",
        "\tfor line in f.readlines():\r\n",
        "\t\tnline = line.replace(\",\", \"\").replace(\".\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\":\", \"\").replace(\"\\\"\",\"\").strip().split(\" \")\r\n",
        "\t\tencode = review_encode(nline)\r\n",
        "\t\tencode = keras.preprocessing.sequence.pad_sequences([encode], value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250) # make the data 250 words long\r\n",
        "\t\tpredict = model.predict(encode)\r\n",
        "\t\tprint(line)\r\n",
        "\t\tprint(encode)\r\n",
        "\t\tprint(predict[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-06eb53c48db5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0mnline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\")\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<PAD>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# make the data 250 words long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test.txt'"
          ]
        }
      ]
    }
  ]
}